{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.65*5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.25*800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8550.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.5*5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20*5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fea743f38e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5169dd87248b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'e'"
     ]
    }
   ],
   "source": [
    "torch.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.exp received an invalid combination of arguments - got (\u001b[31;1mint\u001b[0m), but expected (torch.FloatTensor source)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f92c7b8cba07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: torch.exp received an invalid combination of arguments - got (\u001b[31;1mint\u001b[0m), but expected (torch.FloatTensor source)"
     ]
    }
   ],
   "source": [
    "torch.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 12\n",
    "A = 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = 2*torch.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(A):\n",
    "    a[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = torch.zeros(N,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11    12\n",
       "\n",
       "Columns 13 to 25 \n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "   13    14    15    16    17    18    19    20    21    22    23    24    25\n",
       "\n",
       "Columns 26 to 27 \n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "   26    27\n",
       "[torch.FloatTensor of size 12x28]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.expand_as(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       "[torch.FloatTensor of size 12]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function FloatTensor.t>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.expand(28,12).t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2\n",
       "[torch.FloatTensor of size 28x12]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.expand(28,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = torch.t(mu.expand(28,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "\n",
      "Columns 13 to 25 \n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
      "\n",
      "Columns 26 to 27 \n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "    2     2\n",
      "[torch.FloatTensor of size 12x28]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-cce324aaf12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xd' is not defined"
     ]
    }
   ],
   "source": [
    "print(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 2*torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'expand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-056814e71920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'expand'"
     ]
    }
   ],
   "source": [
    "y = i.expand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-1489b17face4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "i.expand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.FloatTensor with no dimension]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5e8e50802853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "i.expand(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6be7c7fbe025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (-1) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "i.expand(20,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-112da3a299a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "i.expand(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3bb39b62541b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "i.expand(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.arange received an invalid combination of arguments - got (int), but expected one of:\n * (float start, float end)\n * (float start, float end, float step)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-51619060d5be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: torch.arange received an invalid combination of arguments - got (int), but expected one of:\n * (float start, float end)\n * (float start, float end, float step)\n"
     ]
    }
   ],
   "source": [
    "j = 2*torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = 2*torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0\n",
       "  2\n",
       "  4\n",
       "  6\n",
       "  8\n",
       " 10\n",
       " 12\n",
       " 14\n",
       " 16\n",
       " 18\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "    0     2     8    18    32    50    72    98   128   162\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.expand(20,10)*j.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = torch.ones(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "\n",
       "Columns 13 to 19 \n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "[torch.FloatTensor of size 10x20]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-85354fcb12ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "k.expand(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-85c3bf585dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "k.expand(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "\n",
       "Columns 13 to 19 \n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "    1     1     1     1     1     1     1\n",
       "[torch.FloatTensor of size 10x20]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(k.expand(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    3     3     3     3     3     3     3     3     3     3     3     3     3\n",
       "    4     4     4     4     4     4     4     4     4     4     4     4     4\n",
       "    5     5     5     5     5     5     5     5     5     5     5     5     5\n",
       "    6     6     6     6     6     6     6     6     6     6     6     6     6\n",
       "    7     7     7     7     7     7     7     7     7     7     7     7     7\n",
       "    8     8     8     8     8     8     8     8     8     8     8     8     8\n",
       "    9     9     9     9     9     9     9     9     9     9     9     9     9\n",
       "\n",
       "Columns 13 to 19 \n",
       "    0     0     0     0     0     0     0\n",
       "    1     1     1     1     1     1     1\n",
       "    2     2     2     2     2     2     2\n",
       "    3     3     3     3     3     3     3\n",
       "    4     4     4     4     4     4     4\n",
       "    5     5     5     5     5     5     5\n",
       "    6     6     6     6     6     6     6\n",
       "    7     7     7     7     7     7     7\n",
       "    8     8     8     8     8     8     8\n",
       "    9     9     9     9     9     9     9\n",
       "[torch.FloatTensor of size 10x20]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(k.expand(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
       "    2     2     2     2     2     2     2     2     2     2     2     2     2\n",
       "    3     3     3     3     3     3     3     3     3     3     3     3     3\n",
       "    4     4     4     4     4     4     4     4     4     4     4     4     4\n",
       "    5     5     5     5     5     5     5     5     5     5     5     5     5\n",
       "    6     6     6     6     6     6     6     6     6     6     6     6     6\n",
       "    7     7     7     7     7     7     7     7     7     7     7     7     7\n",
       "    8     8     8     8     8     8     8     8     8     8     8     8     8\n",
       "    9     9     9     9     9     9     9     9     9     9     9     9     9\n",
       "\n",
       "Columns 13 to 19 \n",
       "    0     0     0     0     0     0     0\n",
       "    1     1     1     1     1     1     1\n",
       "    2     2     2     2     2     2     2\n",
       "    3     3     3     3     3     3     3\n",
       "    4     4     4     4     4     4     4\n",
       "    5     5     5     5     5     5     5\n",
       "    6     6     6     6     6     6     6\n",
       "    7     7     7     7     7     7     7\n",
       "    8     8     8     8     8     8     8\n",
       "    9     9     9     9     9     9     9\n",
       "[torch.FloatTensor of size 10x20]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(k.expand(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "    0     1     2     3     4     5     6     7     8     9\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = 2*torch.ones(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "    2     2     2     2     2     2     2     2     2     2\n",
      "[torch.FloatTensor of size 20x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "...\n",
       "\n",
       "(37,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(38,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(39,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "[torch.FloatTensor of size 40x20x10]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.expand(40,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(0 ,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(0 ,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(0 ,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(1 ,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(1 ,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(1 ,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(1 ,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(1 ,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(2 ,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(2 ,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(2 ,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(2 ,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(2 ,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(37,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(37,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(37,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(37,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(37,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(37,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ⋮ \n",
       "\n",
       "(38,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(38,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(38,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(38,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(38,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(38,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ⋮ \n",
       "\n",
       "(39,0 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(39,1 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(39,2 ,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   ...\n",
       "\n",
       "(39,27,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(39,28,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "\n",
       "(39,29,.,.) = \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "     ...       ⋱       ...    \n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "   2   2   2  ...    2   2   2\n",
       "[torch.FloatTensor of size 40x30x20x10]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.expand(40,30,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1697  1.1885 -0.5224  0.2091 -1.4592  0.9295  0.0612 -0.8229 -0.0276  0.5443\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1697\n",
       " 1.1885\n",
       "-0.5224\n",
       " 0.2091\n",
       "-1.4592\n",
       " 0.9295\n",
       " 0.0612\n",
       "-0.8229\n",
       "-0.0276\n",
       " 0.5443\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1697  1.1885 -0.5224  0.2091 -1.4592  0.9295  0.0612 -0.8229 -0.0276  0.5443\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-53bc2a3a754f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "v.expand(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-53bc2a3a754f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "v.expand(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-dec113360cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (-1) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "v.expand(20,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-197aa5ffffd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "v.expand(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       "[torch.FloatTensor of size 20x10]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.expand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469\n",
       " 0.5576\n",
       " 0.4667\n",
       " 0.6445\n",
       "-0.6942\n",
       " 1.2380\n",
       "-0.1023\n",
       " 0.1053\n",
       "-0.6335\n",
       " 1.4522\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469  0.5576  0.4667  0.6445 -0.6942  1.2380 -0.1023  0.1053 -0.6335  1.4522\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-5b49e7f4a06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (10) at non-singleton dimension 1. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "v.unsqueeze(0).expand(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.FloatTensor with no dimension]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(0).expand(-1,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = v.unsqueeze(0).expand(-1,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.FloatTensor with no dimension]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1469\n",
       " 0.5576\n",
       " 0.4667\n",
       " 0.6445\n",
       "-0.6942\n",
       " 1.2380\n",
       "-0.1023\n",
       " 0.1053\n",
       "-0.6335\n",
       " 1.4522\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_y = torch.randn(100,12,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_x = torch.randn(100,28,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'expand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-9cfde4ed400d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'expand'"
     ]
    }
   ],
   "source": [
    "x_b = torch.expand(100,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x.expand(100,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-5edd7233c4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_b' is not defined"
     ]
    }
   ],
   "source": [
    "z = torch.bmm(x_b, F_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: expected 3D tensor, got 2D at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensorMath.c:1505",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-327b4ea5db72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 1: expected 3D tensor, got 2D at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensorMath.c:1505"
     ]
    }
   ],
   "source": [
    "z = x.bmm(F_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = y.bmm(F_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       " -2.1565e+00  4.7330e+00  3.6757e+00  ...   5.6558e+00  2.3737e+00  9.3043e-03\n",
       " -1.0160e+01  5.9853e+00 -9.5944e+00  ...   1.9193e+00  6.5359e+00 -4.0541e-01\n",
       "  7.4175e+00  2.5365e-01  6.5610e+00  ...   3.8062e+00 -2.0695e+00  9.9809e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.9532e-01  1.7983e+00 -1.0847e-01  ...  -3.6615e+00 -9.8239e-01  4.1918e+00\n",
       " -7.5664e+00 -8.6400e-01  2.3011e+00  ...   4.0460e+00  4.9743e+00  1.0503e+01\n",
       " -2.3904e+00  4.2203e+00  1.7545e+00  ...   1.1838e+01  3.6603e+00  2.7358e+00\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  2.1820e+00  7.2150e+00 -8.5534e+00  ...  -4.0290e+00 -8.6408e-01 -5.8807e+00\n",
       " -3.4165e+00  6.6874e-01  1.0361e+01  ...   7.0590e+00 -5.3059e+00 -1.0129e+01\n",
       "  4.4550e+00 -3.5638e+00  1.7918e+00  ...  -6.4093e+00 -7.3626e+00  3.6106e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.8447e+00 -2.6960e+00 -2.1235e+00  ...   4.8573e+00 -3.3807e+00  5.1780e+00\n",
       "  4.5450e+00  2.2224e+00  8.3986e+00  ...   6.6395e+00 -8.7782e+00 -4.3788e-01\n",
       " -9.0454e+00 -1.8136e+00 -1.3328e+01  ...  -4.8391e+00 -1.2207e+00 -5.8374e+00\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  1.1871e+01  1.7771e+00  4.6298e+00  ...   4.2416e+00  2.1906e-01 -2.2030e+00\n",
       "  3.3901e+00 -7.2530e+00  1.9675e+00  ...  -2.0657e+00 -3.4586e+00 -9.0769e+00\n",
       "  5.4371e+00 -6.2773e+00 -1.8355e+00  ...  -2.0336e+00  5.4372e+00 -1.0882e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.4565e+00 -3.0896e+00  2.1547e+00  ...  -4.5543e+00 -1.4928e+00  5.7262e+00\n",
       "  5.7147e+00 -9.9006e+00  6.7086e-01  ...   3.1443e+00  2.2274e+00 -1.0369e+01\n",
       "  8.5026e+00 -8.1211e+00 -3.0576e-01  ...   5.5281e+00 -3.5217e+00 -6.6354e+00\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       "  5.7315e-01 -7.5153e-01  5.2358e+00  ...   8.4080e+00  2.9369e+00  1.3896e+00\n",
       " -1.1164e+01 -7.6972e-01  2.3666e+00  ...  -5.6001e+00  1.0556e-01 -7.9111e+00\n",
       "  1.0975e+00  4.6401e+00 -5.0527e+00  ...  -2.1226e+00 -9.5092e-01 -5.2966e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  9.9231e-01  8.8286e-01  9.0604e+00  ...   4.1216e+00 -3.4089e+00 -7.6291e-01\n",
       " -4.6205e+00 -5.3274e-01 -1.2075e+00  ...  -2.9554e+00  5.7807e+00 -1.0757e+01\n",
       "  1.3537e+00  1.1150e+00 -1.4866e+00  ...   2.2148e-01  5.5398e-01 -8.1100e-01\n",
       "\n",
       "(98 ,.,.) = \n",
       " -5.0122e+00 -1.3022e+01 -1.9105e+00  ...   4.0334e+00  3.2483e+00  4.6800e+00\n",
       " -1.7381e+00  4.7078e+00  8.1979e+00  ...   5.5424e-01  2.1952e+00 -2.6135e+00\n",
       " -6.1117e+00  4.1258e-01  1.9413e+00  ...  -9.8802e-01  5.6733e+00 -9.5766e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.1372e+00 -1.2355e+00 -3.6096e+00  ...   4.6688e+00 -3.3601e+00  5.2098e+00\n",
       " -1.6980e+00  2.9883e+00  7.4123e+00  ...  -3.8659e+00  5.7705e+00  4.0743e+00\n",
       " -6.1411e+00 -7.0695e+00  3.0420e+00  ...  -8.8186e-01 -4.3243e-01  1.4829e+00\n",
       "\n",
       "(99 ,.,.) = \n",
       " -2.6531e+00  9.4313e-01  7.8819e-01  ...   1.1950e+00  9.7943e-01 -7.7295e+00\n",
       "  7.3783e+00  2.1919e-01 -8.8185e+00  ...  -5.4787e+00 -6.5319e+00  3.0653e-01\n",
       "  4.8263e-01  1.9952e+00 -4.6392e+00  ...  -7.2706e-01 -1.1867e+00  1.5502e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.1330e-01 -2.1918e+00 -2.4124e+00  ...   2.7705e+00  1.1614e+00 -1.8446e+00\n",
       "  2.8522e+00  6.7918e+00  1.4420e-01  ...  -1.4707e+01  4.9320e-02 -4.1034e+00\n",
       "  8.0102e-01  4.6006e+00 -1.6435e+00  ...  -6.7427e-01 -1.0162e+00  9.1415e+00\n",
       "[torch.FloatTensor of size 100x28x12]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = F_y.bmm(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12, 12])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = torch.zeros(100, 12, 12)\n",
    "for b in range(100):\n",
    "    t = torch.mm(x, F_x[b])\n",
    "    tmp[b] = torch.mm(F_y[b],t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 1 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 2 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(98 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(99 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 100x12x12]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w - tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12, 12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-98adedd141d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pytorch/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mexpand_as\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "gamma.expand_as(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-d4025bd2de36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pytorch/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mexpand_as\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "tmp * gamma.expand_as(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gamme' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-4f5e97b6769c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gamme' is not defined"
     ]
    }
   ],
   "source": [
    "tmp * gamme.expand(100,12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-4e2d309d113a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 2. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "tmp * gamma.expand(100,12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-67356fb4bb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (12) must match the existing size (100) at non-singleton dimension 0. at /opt/conda/conda-bld/pytorch_1502009910772/work/torch/lib/TH/generic/THTensor.c:308"
     ]
    }
   ],
   "source": [
    "gamma.expand(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma.expand(12,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma.expand(12,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8362\n",
       " 0.2848\n",
       "-0.1087\n",
       " 0.2168\n",
       " 0.9209\n",
       "-0.5996\n",
       " 1.1304\n",
       " 0.8982\n",
       " 0.0009\n",
       " 1.9686\n",
       " 0.2510\n",
       " 2.1413\n",
       "-0.4525\n",
       "-0.5449\n",
       "-0.4833\n",
       " 1.0260\n",
       "-0.3584\n",
       " 0.1197\n",
       " 0.4460\n",
       " 0.1227\n",
       "-1.3245\n",
       " 1.1673\n",
       "-1.0832\n",
       " 0.8552\n",
       "-1.1226\n",
       " 1.3835\n",
       "-0.8157\n",
       " 0.9208\n",
       "-0.3631\n",
       " 1.0295\n",
       " 1.6788\n",
       "-0.3167\n",
       "-0.0425\n",
       "-0.5505\n",
       " 0.0906\n",
       " 0.8790\n",
       "-1.8688\n",
       " 0.5346\n",
       " 0.4710\n",
       " 1.4012\n",
       "-0.6211\n",
       " 0.1306\n",
       "-0.6447\n",
       "-0.9671\n",
       " 0.9377\n",
       " 0.9745\n",
       "-0.5474\n",
       "-0.2336\n",
       "-0.5602\n",
       " 0.1481\n",
       " 2.3759\n",
       " 1.2144\n",
       " 0.9803\n",
       " 0.6710\n",
       "-1.5745\n",
       " 0.5433\n",
       " 0.3368\n",
       " 0.3009\n",
       " 0.6959\n",
       "-0.3418\n",
       " 0.3553\n",
       "-0.0049\n",
       " 0.8835\n",
       " 2.0587\n",
       "-0.0801\n",
       "-0.4458\n",
       "-1.8674\n",
       " 0.7985\n",
       "-0.6188\n",
       " 0.2338\n",
       "-1.7515\n",
       " 2.2963\n",
       " 1.1057\n",
       "-1.5561\n",
       "-0.3817\n",
       " 0.9230\n",
       " 0.9519\n",
       " 0.9766\n",
       " 0.4001\n",
       "-1.5149\n",
       " 0.6432\n",
       " 0.3321\n",
       " 1.1986\n",
       " 2.1120\n",
       "-0.1033\n",
       "-1.4074\n",
       " 0.4984\n",
       "-1.1930\n",
       " 2.3157\n",
       " 0.1603\n",
       " 0.3958\n",
       " 0.1641\n",
       "-1.2959\n",
       "-1.5625\n",
       " 1.1534\n",
       " 1.2524\n",
       "-2.1807\n",
       " 1.0272\n",
       "-0.0363\n",
       " 3.0702\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = gamma.expand(12,12,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12, 100])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid permutation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-e77af26387ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pytorch/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mpermute\u001b[0;34m(self, *dims)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Invalid permutation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid permutation"
     ]
    }
   ],
   "source": [
    "g = g.permute(3,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = g.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "  2.1076e+00 -3.6104e+01  1.0193e+01  ...   2.2599e+00  2.4896e+01 -1.4667e+01\n",
       "  1.1866e+01 -8.2317e+00 -1.0224e+01  ...  -2.9284e+01  1.1745e+01 -6.0133e+01\n",
       "  3.0057e+01 -3.8772e+01  2.0215e+01  ...  -3.7653e+00  4.4003e+01 -5.5445e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  3.0206e+01 -6.7104e+00 -7.6708e-01  ...  -7.2204e+01 -3.0146e+01 -4.1839e+01\n",
       " -3.1962e+01  2.3190e+01 -2.7972e+00  ...  -1.2761e+01  3.9204e+00  4.0550e+00\n",
       "  3.3164e+01 -1.8685e+01  2.1495e+01  ...  -5.0039e+00 -3.6384e+01  5.7009e+00\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  1.0387e+01  1.0642e+00 -6.6961e+00  ...  -4.1110e+00  5.3000e+00  2.1991e+00\n",
       " -9.9069e+00 -2.0745e+00 -1.0554e+01  ...   5.2388e+00  1.6428e+01 -1.6370e+01\n",
       "  3.6098e+00  6.0197e+00  1.7331e+01  ...  -4.4790e+00 -2.7523e+00 -1.2652e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.1324e+01 -1.1733e+01 -4.3445e-01  ...  -4.0776e+00  2.9701e+00  1.2219e+01\n",
       "  1.4854e-01 -7.5411e+00  5.7213e+00  ...  -2.4884e+00 -8.5399e+00  1.9168e-01\n",
       "  5.5038e+00 -4.6480e+00 -5.0341e-01  ...  -7.1175e+00 -1.0586e+01  4.7555e-02\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -2.6309e+00  2.0380e+00 -6.9638e-01  ...   1.0241e-01  1.0168e+00  5.3170e+00\n",
       " -3.8853e+00  2.5645e+00  8.9297e-02  ...  -6.9265e-01  2.2675e+00  4.3775e-02\n",
       "  2.4234e+00  6.4528e-01  2.8755e+00  ...  -3.2625e+00 -2.4227e-01 -6.5858e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  5.0418e+00  2.2496e-01  1.9910e+00  ...  -1.5438e+00 -5.2384e-01 -1.1323e+00\n",
       " -6.3750e+00 -1.0129e+00  3.2361e+00  ...  -3.4972e+00  3.8885e+00  2.0608e-01\n",
       "  4.6529e+00 -3.2790e+00  2.5869e-01  ...   1.3463e+00  5.3326e+00 -2.1422e+00\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       "  2.5507e+01 -9.5861e+00  5.9038e+00  ...   3.8304e+01  2.5636e+00  3.6658e+01\n",
       "  2.7426e+01  3.6810e+00  1.0019e+01  ...  -5.7540e-02 -2.8569e+01 -1.1724e+01\n",
       "  1.8735e+01  2.0491e+01 -8.3456e+01  ...  -2.3346e+00  1.2126e+01  4.4610e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  3.0540e+01  1.3822e+01 -4.6518e+00  ...   6.2353e+01  7.0595e-01  1.0877e+01\n",
       "  2.0924e+00  1.4054e+01 -2.6019e+01  ...  -3.9717e+01 -2.6895e+01 -3.5584e+01\n",
       " -3.1057e+00 -1.0495e+01 -2.8993e+00  ...   2.9216e+00  1.1054e+01 -1.3963e+01\n",
       "\n",
       "(98 ,.,.) = \n",
       "  3.2643e-01 -8.0292e-01  1.3623e+00  ...  -1.7474e+00  6.7572e-01 -1.8383e+00\n",
       " -1.4513e+00  2.7078e-01  5.0467e-01  ...  -6.4976e-01  9.8584e-01  1.4085e-01\n",
       "  2.2684e-01  2.0717e-01 -1.7349e-02  ...  -2.5065e-01 -7.2745e-01  9.4228e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  7.8819e-02  4.7573e-02 -8.0243e-01  ...   1.0397e+00 -1.0996e+00 -7.9876e-01\n",
       "  2.3383e-01  1.0171e+00  1.2355e+00  ...  -9.4188e-02 -1.8972e+00  1.3103e+00\n",
       "  1.0021e+00  3.4686e-01 -1.2670e-01  ...   6.0156e-01  9.6490e-01  1.0050e+00\n",
       "\n",
       "(99 ,.,.) = \n",
       " -7.1834e+01 -1.2164e+01 -4.3806e+01  ...   1.9407e+01  5.5773e+01  1.1830e+02\n",
       "  1.1615e+01  4.3411e+01 -3.1606e+01  ...  -1.4561e+02  1.6931e+01 -1.0539e+02\n",
       " -5.1623e+01  2.2479e+01 -4.4894e+01  ...  -3.2482e+01  1.6634e+01  7.8036e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  3.3385e+01  8.0327e+01 -3.1711e+01  ...  -1.3619e+02  2.8439e+01 -6.3320e+01\n",
       "  1.5489e+01 -1.2466e+00  2.5146e+01  ...   5.0675e+01  1.5361e+01 -7.3887e+01\n",
       " -5.8678e+01 -1.3523e+01  2.1502e+01  ...   2.2272e+01  1.2131e+01  7.8423e+01\n",
       "[torch.FloatTensor of size 100x12x12]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#09/19/2017\n",
    "#Implement  v = gamma . F_y . x . F_x_t\n",
    "A = 28\n",
    "B = 28\n",
    "N = 12\n",
    "bsz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_y = torch.randn(bsz, N, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_x = torch.randn(bsz, N, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(bsz, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = torch.randn(bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "  3.2344e+00 -3.3385e+00  2.8618e+00  ...   2.2531e+00 -2.2896e+00  1.1199e+00\n",
       "  9.3746e+00  1.1098e+01 -3.6846e-01  ...  -3.3425e+00  7.2589e+00  4.4836e+00\n",
       " -1.8128e+00 -8.6770e-01 -8.0171e+00  ...   1.6208e+00  3.8913e+00 -1.7269e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  7.7159e+00 -1.6883e+00 -7.4532e+00  ...   1.1281e+00 -3.1314e+00 -2.6792e-01\n",
       " -3.8201e+00  1.5945e+00 -3.3485e+00  ...  -4.3329e+00  5.0487e+00  8.5744e-01\n",
       " -1.3438e+00  5.3329e+00  1.6475e+00  ...   3.8830e+00  9.8194e+00  4.1374e+00\n",
       "\n",
       "( 1 ,.,.) = \n",
       " -5.2569e-01 -1.3634e+00 -2.9081e+00  ...   4.9177e+00 -4.4658e+00 -7.1473e-01\n",
       "  4.6355e+00 -6.6809e+00 -1.9504e+00  ...  -4.6013e+00  5.4413e+00  7.1788e+00\n",
       "  9.0214e+00  9.6237e+00  1.1311e+00  ...   4.0526e+00  6.7106e+00 -1.7108e+00\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.0075e+01 -4.6826e+00  3.9035e-01  ...  -7.6460e+00  5.3571e+00  4.8537e-01\n",
       "  4.6548e-01 -7.6873e+00 -2.7628e+00  ...   1.3307e+00 -2.2436e+00  5.5553e+00\n",
       " -5.1125e+00 -5.3827e+00 -4.6531e-01  ...   6.8729e+00  4.4310e+00  1.7892e+00\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  1.1523e+00  7.4492e-01 -9.1605e+00  ...  -3.7526e+00  5.0158e+00 -1.7792e+00\n",
       " -6.8627e-01 -5.0782e+00 -2.6787e+00  ...  -7.3967e+00  5.3883e+00  1.0528e+00\n",
       "  1.9028e+00 -1.0002e+01 -7.1960e+00  ...   2.2081e+00  2.2116e-01 -1.6399e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  6.8329e+00  4.4552e+00  3.9973e+00  ...   2.8657e+00  2.2935e+00  2.1446e-01\n",
       " -9.4435e+00  6.3839e+00  4.9565e+00  ...  -2.3131e+00  4.7562e+00 -3.0455e+00\n",
       "  1.4852e+00  8.1203e+00  7.5560e+00  ...  -3.1133e+00 -3.9470e+00 -7.1120e+00\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       " -4.2946e+00 -1.3108e-01 -6.7707e+00  ...  -4.3104e+00  3.6201e+00  1.1115e+01\n",
       " -2.1260e+00  8.7305e-01 -4.0871e-01  ...  -3.5711e+00  2.3352e+00  3.2918e-01\n",
       " -3.3794e+00 -1.2086e+00 -1.4542e+00  ...   4.2463e+00 -3.4401e-01  8.1644e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -5.4498e+00  9.3388e+00  9.4738e-01  ...  -4.6074e+00 -3.1034e+00 -2.0907e+00\n",
       " -4.0091e-01  5.8780e+00  9.1576e+00  ...   4.9942e+00 -2.4566e+00  1.5679e+00\n",
       "  3.3632e+00  4.3801e+00  1.0215e+01  ...   3.1446e+00 -5.1233e+00  3.7887e+00\n",
       "\n",
       "(98 ,.,.) = \n",
       " -8.5893e+00 -1.4762e+00 -8.1700e+00  ...  -3.7869e+00 -1.1733e+01 -4.8044e+00\n",
       "  1.6959e+00 -4.6448e+00 -2.7357e+00  ...  -3.8539e+00 -6.8515e+00 -7.3001e-01\n",
       " -3.0410e+00 -3.5324e+00 -1.5958e+00  ...   1.7669e+00 -2.5707e+00 -5.4646e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.5772e+00  1.4100e+01  4.3825e+00  ...  -5.8715e+00  1.0203e+01  5.3801e+00\n",
       "  5.3070e+00  4.3368e+00 -3.6689e+00  ...  -3.3911e+00 -2.1172e+00  6.0412e+00\n",
       " -2.9997e+00  6.6974e+00 -6.0630e+00  ...   6.6749e-01  7.8099e+00  6.3484e-01\n",
       "\n",
       "(99 ,.,.) = \n",
       " -7.7220e+00  3.5270e+00 -6.7686e+00  ...   4.1553e+00 -4.5159e+00  3.2041e+00\n",
       " -5.4301e+00 -9.0836e+00 -1.5599e+00  ...  -4.3129e+00 -1.2320e+00 -3.8627e+00\n",
       " -6.9616e+00 -2.8016e+00  4.8270e+00  ...  -7.3223e+00 -2.4069e+00 -4.1758e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.2199e+00  4.8278e+00 -9.2807e+00  ...   1.4166e+01  3.9333e+00 -2.1306e+00\n",
       "  1.6228e+00  1.6757e+01  9.4284e-01  ...  -3.4730e+00  2.2344e+00 -1.8602e+00\n",
       " -4.5698e+00 -3.1351e+00 -6.5401e+00  ...   9.0713e+00  3.4863e+00  1.5949e+01\n",
       "[torch.FloatTensor of size 100x28x12]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.bmm(F_x.permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       " -8.0124e+00 -2.6880e+01 -1.4915e+01  ...  -2.6372e+01 -1.7088e+01 -8.2933e+00\n",
       " -1.3010e+01  2.8468e+01 -4.8618e+01  ...  -3.3370e+01 -1.0214e+01 -3.3313e+01\n",
       " -3.9728e+01 -1.1114e+01 -1.4810e+01  ...  -2.1950e+01 -6.9564e+00 -1.6063e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -2.2031e+00  2.1782e+00 -5.1517e+01  ...  -1.6210e+01 -6.3582e+00 -2.6669e+01\n",
       " -2.8089e+01 -5.7909e+01 -1.4745e+01  ...   4.7785e+01 -2.1941e+01  2.9618e+01\n",
       "  3.9435e+01  5.2729e+01 -4.2150e+01  ...  -6.7568e+01  7.4808e+00 -3.5965e+01\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  3.3549e+01 -6.6311e+00  1.7343e+01  ...  -7.7839e+00 -1.3862e+01  1.6658e+01\n",
       " -6.9661e+00  1.7506e+01  5.8190e+00  ...   2.1799e+01  1.1504e+01 -1.1286e+01\n",
       " -5.5107e+01 -1.4498e+01 -1.7684e+01  ...   1.3809e+01 -5.6366e+01  2.3147e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  8.2403e+01  2.2796e+01 -1.0270e+01  ...   1.5486e+01 -7.9383e+01 -1.4732e+01\n",
       " -1.5326e+01 -1.9395e+01 -1.9877e+01  ...   2.9888e+01  8.8394e-01 -1.6266e+00\n",
       "  5.9740e+01  4.1261e+01  5.9892e+00  ...   3.4066e+01  1.8678e+01  2.1804e+01\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  1.1638e+01 -3.8160e+01  2.4254e+01  ...   3.8741e+01  1.6213e+01 -1.5783e+01\n",
       "  1.3185e+00 -9.3594e+00 -1.0297e+01  ...  -8.9694e+00 -1.0925e+01  1.5112e+01\n",
       " -9.4957e+00  1.7531e+01  5.4113e+01  ...   2.5758e+01 -2.7719e+01  1.3524e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -2.4067e+01  1.7783e+01  1.2064e+01  ...  -5.5902e+00 -3.9523e+00 -1.5372e+00\n",
       " -2.5060e+01  1.2983e+00 -4.8002e+00  ...  -3.5747e+01  1.9391e+01 -6.3695e+01\n",
       "  5.2597e+01 -3.2036e+01 -3.3308e+01  ...   1.0137e+01 -4.0257e+01  5.3396e+00\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       "  4.9556e+00  2.9654e-01 -1.6371e+01  ...   1.7945e+01  7.6974e+00  8.1367e+00\n",
       " -1.7390e+01 -3.7997e+01 -6.3608e+01  ...  -1.8945e+01  2.4441e+01  5.7774e+01\n",
       " -4.1543e+00  2.1587e+00  9.4224e+00  ...   2.3632e+00  1.7738e+01  2.5067e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.4919e+01  1.1035e+01 -7.9877e+00  ...  -4.4219e+01 -8.5716e+00 -2.3733e+01\n",
       " -1.8149e+01  3.3838e+01  4.3704e+01  ...   2.3537e+01 -1.3479e+00  3.3989e+00\n",
       " -2.1577e+01  8.8046e+00 -1.8706e+01  ...  -4.6414e+01  1.2443e+01 -5.1009e+01\n",
       "\n",
       "(98 ,.,.) = \n",
       "  9.0996e+00  1.4034e+01  2.1475e+01  ...   4.9396e+00 -1.5410e+01  3.0330e+00\n",
       "  2.4378e+01 -1.9631e+01 -4.0141e+01  ...  -1.2246e+00 -4.9443e+01  2.5037e+00\n",
       " -1.5667e+01  1.9710e+01 -6.4580e+01  ...  -1.2047e+01 -6.3378e+01  1.3018e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.2568e+01 -2.5732e+01 -5.7302e+00  ...  -1.5279e+01 -3.5507e+01  2.4351e+00\n",
       " -3.3733e+01 -1.1050e+02 -1.5786e+01  ...   2.3282e+01 -1.0208e+02 -4.9366e+01\n",
       " -9.5567e+00 -6.6944e+00 -2.1202e+01  ...  -8.2229e+00  1.1339e+01  1.3614e+01\n",
       "\n",
       "(99 ,.,.) = \n",
       "  3.1844e+01 -2.9942e+01  5.0618e+00  ...   3.5411e+01 -1.6341e+01  3.9928e+01\n",
       "  2.7067e+01 -5.5460e+01  6.7901e+01  ...  -5.6781e+01  1.5838e+01 -2.4284e+01\n",
       "  2.9443e+01  4.8109e+00  7.5166e+01  ...  -2.6238e+01 -7.8651e+00 -4.3450e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  4.9065e+01  5.5204e+01 -3.5515e+00  ...   4.3687e+01 -2.5921e+01  3.3623e+01\n",
       " -1.4054e+01  3.1522e+01  1.5312e+01  ...  -2.7178e+00 -8.1818e-02  1.0408e+01\n",
       " -4.0857e+01  4.0088e+01  2.7656e+01  ...   4.1020e+00  5.6384e-01  2.0027e+01\n",
       "[torch.FloatTensor of size 100x12x12]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_y.bmm(x.bmm(F_x.permute(0,2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "\n",
       "( 1 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "... \n",
       "\n",
       "( 9 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "\n",
       "(10 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "\n",
       "(11 ,.,.) = \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       " -1.3077  0.9937 -0.3807  ...  -0.1712  0.2278 -1.3192\n",
       "[torch.FloatTensor of size 12x12x100]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.expand(N, N, bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       "           ...             ⋱             ...          \n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       " -1.3077 -1.3077 -1.3077  ...  -1.3077 -1.3077 -1.3077\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "           ...             ⋱             ...          \n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "  0.9937  0.9937  0.9937  ...   0.9937  0.9937  0.9937\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       "           ...             ⋱             ...          \n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       " -0.3807 -0.3807 -0.3807  ...  -0.3807 -0.3807 -0.3807\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       "           ...             ⋱             ...          \n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       " -0.1712 -0.1712 -0.1712  ...  -0.1712 -0.1712 -0.1712\n",
       "\n",
       "(98 ,.,.) = \n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "           ...             ⋱             ...          \n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "  0.2278  0.2278  0.2278  ...   0.2278  0.2278  0.2278\n",
       "\n",
       "(99 ,.,.) = \n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       "           ...             ⋱             ...          \n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       " -1.3192 -1.3192 -1.3192  ...  -1.3192 -1.3192 -1.3192\n",
       "[torch.FloatTensor of size 100x12x12]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.expand(N, N, bsz).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "  1.0478e+01  3.5151e+01  1.9504e+01  ...   3.4487e+01  2.2346e+01  1.0845e+01\n",
       "  1.7013e+01 -3.7227e+01  6.3577e+01  ...   4.3638e+01  1.3356e+01  4.3563e+01\n",
       "  5.1952e+01  1.4533e+01  1.9366e+01  ...   2.8704e+01  9.0968e+00  2.1005e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.8810e+00 -2.8485e+00  6.7368e+01  ...   2.1198e+01  8.3145e+00  3.4874e+01\n",
       "  3.6731e+01  7.5727e+01  1.9282e+01  ...  -6.2488e+01  2.8692e+01 -3.8732e+01\n",
       " -5.1569e+01 -6.8952e+01  5.5119e+01  ...   8.8358e+01 -9.7826e+00  4.7031e+01\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  3.3338e+01 -6.5894e+00  1.7234e+01  ...  -7.7350e+00 -1.3775e+01  1.6553e+01\n",
       " -6.9223e+00  1.7396e+01  5.7825e+00  ...   2.1662e+01  1.1432e+01 -1.1215e+01\n",
       " -5.4761e+01 -1.4407e+01 -1.7573e+01  ...   1.3722e+01 -5.6012e+01  2.3002e+01\n",
       "                 ...                   ⋱                   ...                \n",
       "  8.1885e+01  2.2653e+01 -1.0205e+01  ...   1.5389e+01 -7.8884e+01 -1.4640e+01\n",
       " -1.5230e+01 -1.9273e+01 -1.9753e+01  ...   2.9701e+01  8.7839e-01 -1.6164e+00\n",
       "  5.9365e+01  4.1002e+01  5.9515e+00  ...   3.3852e+01  1.8561e+01  2.1667e+01\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -4.4307e+00  1.4528e+01 -9.2334e+00  ...  -1.4749e+01 -6.1723e+00  6.0085e+00\n",
       " -5.0195e-01  3.5631e+00  3.9199e+00  ...   3.4147e+00  4.1592e+00 -5.7532e+00\n",
       "  3.6150e+00 -6.6742e+00 -2.0601e+01  ...  -9.8061e+00  1.0552e+01 -5.1488e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  9.1623e+00 -6.7700e+00 -4.5929e+00  ...   2.1282e+00  1.5047e+00  5.8520e-01\n",
       "  9.5404e+00 -4.9428e-01  1.8274e+00  ...   1.3609e+01 -7.3820e+00  2.4249e+01\n",
       " -2.0024e+01  1.2196e+01  1.2680e+01  ...  -3.8590e+00  1.5326e+01 -2.0328e+00\n",
       "... \n",
       "\n",
       "(97 ,.,.) = \n",
       " -8.4827e-01 -5.0759e-02  2.8022e+00  ...  -3.0717e+00 -1.3176e+00 -1.3928e+00\n",
       "  2.9767e+00  6.5041e+00  1.0888e+01  ...   3.2429e+00 -4.1837e+00 -9.8895e+00\n",
       "  7.1111e-01 -3.6952e-01 -1.6129e+00  ...  -4.0451e-01 -3.0362e+00 -4.2909e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.5537e+00 -1.8889e+00  1.3673e+00  ...   7.5692e+00  1.4672e+00  4.0624e+00\n",
       "  3.1066e+00 -5.7922e+00 -7.4811e+00  ...  -4.0290e+00  2.3073e-01 -5.8181e-01\n",
       "  3.6935e+00 -1.5071e+00  3.2020e+00  ...   7.9448e+00 -2.1298e+00  8.7315e+00\n",
       "\n",
       "(98 ,.,.) = \n",
       "  2.0731e+00  3.1973e+00  4.8925e+00  ...   1.1253e+00 -3.5108e+00  6.9098e-01\n",
       "  5.5538e+00 -4.4723e+00 -9.1450e+00  ...  -2.7898e-01 -1.1264e+01  5.7039e-01\n",
       " -3.5693e+00  4.4903e+00 -1.4713e+01  ...  -2.7446e+00 -1.4439e+01  2.9658e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.8632e+00 -5.8624e+00 -1.3055e+00  ...  -3.4808e+00 -8.0892e+00  5.5476e-01\n",
       " -7.6852e+00 -2.5175e+01 -3.5964e+00  ...   5.3042e+00 -2.3257e+01 -1.1247e+01\n",
       " -2.1772e+00 -1.5251e+00 -4.8303e+00  ...  -1.8734e+00  2.5833e+00  3.1016e+00\n",
       "\n",
       "(99 ,.,.) = \n",
       " -4.2007e+01  3.9498e+01 -6.6773e+00  ...  -4.6713e+01  2.1557e+01 -5.2671e+01\n",
       " -3.5705e+01  7.3161e+01 -8.9572e+01  ...   7.4903e+01 -2.0892e+01  3.2034e+01\n",
       " -3.8840e+01 -6.3463e+00 -9.9156e+01  ...   3.4613e+01  1.0375e+01  5.7318e+01\n",
       "                 ...                   ⋱                   ...                \n",
       " -6.4725e+01 -7.2823e+01  4.6850e+00  ...  -5.7630e+01  3.4194e+01 -4.4355e+01\n",
       "  1.8539e+01 -4.1582e+01 -2.0199e+01  ...   3.5852e+00  1.0793e-01 -1.3730e+01\n",
       "  5.3897e+01 -5.2883e+01 -3.6483e+01  ...  -5.4112e+00 -7.4379e-01 -2.6419e+01\n",
       "[torch.FloatTensor of size 100x12x12]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.expand(N, N, bsz).permute(2,0,1) * F_y.bmm(x.bmm(F_x.permute(0,2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'ones_like'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-8054c06dd4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'ones_like'"
     ]
    }
   ],
   "source": [
    "torch.ones_like(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.3077\n",
       " 0.9937\n",
       "-0.3807\n",
       "-0.1353\n",
       " 0.3803\n",
       " 1.7239\n",
       "-0.6129\n",
       " 0.7632\n",
       " 0.5326\n",
       " 1.1526\n",
       "-0.2048\n",
       " 0.4870\n",
       "-3.0108\n",
       "-0.6548\n",
       " 0.7545\n",
       " 1.4604\n",
       " 0.4653\n",
       "-0.2088\n",
       " 0.2393\n",
       "-0.5910\n",
       "-0.9434\n",
       " 1.0172\n",
       "-0.0432\n",
       "-0.4801\n",
       "-2.0621\n",
       "-2.1300\n",
       " 1.2026\n",
       " 1.0315\n",
       "-0.0048\n",
       " 0.7538\n",
       "-0.0254\n",
       "-0.6895\n",
       "-0.6755\n",
       "-1.1738\n",
       "-2.1042\n",
       " 0.1934\n",
       "-0.0129\n",
       "-0.6730\n",
       "-0.9696\n",
       " 0.5140\n",
       " 1.2463\n",
       "-0.3205\n",
       "-0.1466\n",
       " 1.5121\n",
       "-0.9008\n",
       "-0.3545\n",
       "-0.6660\n",
       "-0.0852\n",
       " 0.6309\n",
       " 0.1101\n",
       "-0.9140\n",
       "-2.4640\n",
       " 2.0492\n",
       " 0.4093\n",
       "-0.1311\n",
       "-0.1257\n",
       " 0.8926\n",
       "-1.1658\n",
       " 1.6047\n",
       " 0.7823\n",
       "-0.0732\n",
       "-0.1696\n",
       " 0.2305\n",
       " 0.0455\n",
       "-0.4775\n",
       " 0.9450\n",
       " 1.0818\n",
       "-0.0495\n",
       " 2.4175\n",
       " 0.0221\n",
       "-0.5965\n",
       " 1.6697\n",
       " 0.7213\n",
       "-0.5901\n",
       "-0.2453\n",
       "-0.2734\n",
       " 1.3991\n",
       "-0.0283\n",
       "-0.9845\n",
       "-0.4734\n",
       "-1.0402\n",
       "-0.3107\n",
       " 1.1498\n",
       "-1.6778\n",
       "-0.0817\n",
       " 0.2241\n",
       " 0.6591\n",
       " 0.3851\n",
       "-0.3281\n",
       "-1.3682\n",
       "-1.5770\n",
       "-0.6411\n",
       " 0.5461\n",
       "-0.7268\n",
       " 1.1618\n",
       "-0.3492\n",
       "-2.1180\n",
       "-0.1712\n",
       " 0.2278\n",
       "-1.3192\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'ones_like'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-0ef21c9abc1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'ones_like'"
     ]
    }
   ],
   "source": [
    "torch.ones_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.4001\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
